{
  "copyright_text": null,
  "description": "Deep learning grows in popularity and use, but it has two problems. Neural networks have millions of parameters and provide no uncertainty. In this talk, we solve both problems with one simple trick: Bayesian deep learning. We show how to prune 90% of the parameters while maintaining performance. As a bonus, we get the uncertainty over our predictions, which is useful for critical applications.\n\nSlides: /redirect?redir_token=slkdaFLfFTJbr7O-oUEUnuix1md8MTUzMjc1ODc3OEAxNTMyNjcyMzc4&event=video_description&v=Z7VN7oRA6TY&q=https%3A%2F%2Fgithub.com%2FRobRomijnders%2Fweight_uncertainty%2Fblob%2Fmaster%2Fdocs%2Fpresentation%2Fversions%2Ffinal_pydata18_bayes_nn_rob_romijnders_1.pdf",
  "duration": 2141,
  "language": "eng",
  "recorded": "2018-06-26",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://pydata.org/amsterdam2018/schedule/"
    }
  ],
  "speakers": [
    "Rob Romijnders"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/Z7VN7oRA6TY/maxresdefault.jpg",
  "title": "Bayesian Deep learning with 10% of the weights",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=Z7VN7oRA6TY"
    }
  ]
}
