{
  "copyright_text": "Standard YouTube License",
  "description": "PyData London 2016\n\nThis talk discusses the process of building data pipelines, e.g. extraction, cleaning, integration, pre-processing of data, in general all the steps that are necessary to prepare your data for your data-driven product. In particular, the focus is on data plumbing and on the practice of going from prototype to production.\n\nThis talk discusses the process of building data pipelines, e.g. extraction, cleaning, integration, pre-processing of data, in general all the steps that are necessary to prepare your data for your data-driven product. In particular, the focus is on data plumbing and on the practice of going from prototype to production.\n\nStarting from some common anti-patterns, we'll highlight the need for a workflow manager for any non-trivial project.\n\nWe'll discuss the case for Luigi as an interesting option to consider, and we'll consider where it fits in the bigger picture of deploying a data product.\n\nSlides available here: https://speakerdeck.com/marcobonzanini/building-data-pipelines-in-python-pydata-london-2016",
  "duration": 2262,
  "id": 5233,
  "language": "eng",
  "recorded": "2016-05-11",
  "related_urls": [
    "https://speakerdeck.com/marcobonzanini/building-data-pipelines-in-python-pydata-london-2016"
  ],
  "slug": "marco-bonzanini-building-data-pipelines-in-python-1",
  "speakers": [
    "Marco Bonzanini"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/GUI-gAPh9sU/maxresdefault.jpg",
  "title": "Building Data Pipelines in Python",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=GUI-gAPh9sU"
    }
  ]
}
