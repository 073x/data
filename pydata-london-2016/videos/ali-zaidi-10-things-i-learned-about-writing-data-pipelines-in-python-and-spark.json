{
  "copyright_text": "Standard YouTube License",
  "description": "PyData London 2016\n\nStarting in the Q4, 2015, I wrote the financials data pipeline that collates ~200 data points and calculates ~300 metrics for ~80M account filings from ~11M private companies.\n\nAs I write, this is in production: http://bit.ly/1T3CzDG, http://bit.ly/1Q8iBBq.\n\nI used Python, Spark and loads of good fortune to make this. I would like to share my journey with the PyData community - purely to give something back, as I have learned so much out of the meetups.\n\nMy talk would include takeaways, patterns, anti-patterns, mistakes and big mistakes that I made and learned from. I think this will be very useful for beginner-intermediate data wranglers.\n\nSlides available here: https://github.com/alixedi/PyData2016/blob/master/Enhanced%20Financials.pdf\n\nGitHub: https://github.com/alixedi/PyData2016",
  "duration": 2314,
  "id": 5199,
  "language": "eng",
  "recorded": "2016-05-08",
  "related_urls": [
    "http://bit.ly/1Q8iBBq.",
    "http://bit.ly/1T3CzDG,",
    "https://github.com/alixedi/PyData2016",
    "https://github.com/alixedi/PyData2016/blob/master/Enhanced%20Financials.pdf"
  ],
  "slug": "ali-zaidi-10-things-i-learned-about-writing-data-pipelines-in-python-and-spark",
  "speakers": [
    "Ali Zaidi"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/I21_sZHjfkE/maxresdefault.jpg",
  "title": "10 things I learned about writing data pipelines in Python and Spark.",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=I21_sZHjfkE"
    }
  ]
}
