{
  "description": "EuroSciPy 2019 Bilbao \nSeptember 5, Thursday \nBaroja. Talk. 10.30\n\nVisual Diagnostics at Scale\nDr. Rebecca Bilbro\n\nMachine learning is a search for the best combination of features, model, and hyperparameters. But as data grow, so does the search space! Fortunately, visual diagnostics can focus our search and allow us to steer modeling purposefully, and at scale.\n\nEven with a modestly-sized dataset, the hunt for the most effective machine learning model is hard. Arriving at the optimal combination of features, algorithm, and hyperparameters frequently requires significant experimentation and iteration. This leads some of us to stay inside algorithmic comfort zones, some to trail off on random walks, and others to resort to automated processes like gridsearch. But whatever path we take, we are often left in doubt about whether our final solution really is the optimal one. And as our datasets grow in size and dimension, so too does this ambiguity.\n\nFortunately, many of us have developed strategies for steering model search. Open source libraries like seaborn, pandas and yellowbrick can help make machine learning more informed with visual diagnostic tools like histograms, correlation matrices, parallel coordinates, manifold embeddings, validation and learning curves, residuals plots, and classification heatmaps. These tools enable us to tune our models with visceral cues that allow us to be more strategic in our choices. Visualizing feature transformations, algorithmic behavior, cross-validation methods, and model performance allows us a peek into the multi-dimensional realm in which our models operate.\n\nHowever, large, high-dimensional datasets can prove particularly difficult to explore. Not only do the majority of people struggle to visualize anything beyond two- or three-dimensional space, many of our favorite open source Python tools are not designed to be performant with arbitrarily big data. So how well do our favorite visualization techniques hold up to large, complex datasets?\n\nIn this talk, we'll consider a suite of visual diagnostics \u2014 some familiar and some new \u2014 and explore their strengths and weaknesses with several publicly available datasets of varying size. Which suffer most from the curse of dimensionality in face of increasingly big data? What are the workarounds (e.g. sampling, brushing, filtering, etc.) and when should we use them? And most importantly, how can we continue to steer the machine learning process \u2014 not only purposefully but at scale?\n\nAbstract as a tweet \u2013 How to do #machinelearning thoughtfully AND at scale? Use Scikit-Yellowbrick to visualize feature selection, model evaluation, and hyperparameter and steer towards more informed modeling! \n\nProject Homepage / Git \u2013 https://github.com/districtdatalabs/yellowbrick \nPython Skill Level \u2013 basic \nDomain Expertise \u2013 none \nProject Homepage / Git \u2013 https://github.com/districtdatalabs/yellowbrick \nDomains \u2013 Big Data, Data Visualisation, Machine Learning, Open Source",
  "duration": 1773,
  "published_at": "2020-03-06T15:54:33.000Z",
  "recorded": "",
  "speakers": [],
  "thumbnail_url": "https://i.ytimg.com/vi/3-3BH-PNECk/hqdefault.jpg",
  "title": "EuroSciPy 2019 Bilbao - Visual Diagnostics at Scale - Rebecca Bilbro",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=3-3BH-PNECk"
    }
  ]
}