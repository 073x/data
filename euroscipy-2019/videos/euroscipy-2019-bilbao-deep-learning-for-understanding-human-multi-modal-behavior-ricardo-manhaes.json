{
  "description": "EuroSciPy 2019 Bilbao \nSeptember 5, Thursday \nMitxelena. Talk. 15.45\n\nDeep Learning for Understanding Human Multi-modal Behavior\nRicardo Manh\u00e3es Savii \n\nMulti-modal sources of information are the next big step for AI. In this talk, I will present the use of deep learning techniques for automated multi-modal applications and some open benchmarks.\n\nMultimedia automatic learning has drawn attention from companies and governments for a significant number of applications for automated recommendations, classification, and human brain understatement. In recent years, and an increased amount of research has explored using deep neural networks for multimedia related tasks.\n\nSome government security and surveillance applications are automated detections of illegal and violent behaviors, child pornography and traffic infractions. Companies worldwide are looking for content-based recommendation systems that can personalize clients consumption and interactions by understanding the human perception of memorability, interestingness, attractiveness, aesthetics. For these fields like event detection, multimedia affect and perceptual analysis are turning towards Artificial Neural Networks. In this talk, I will present the theory behind multi-modal fusion using deep learning and some open challenges and their state-of-the-art.\n\nAbstract as a tweet \u2013 Understanding multi-modalities with deep learning approaches \nPython Skill Level \u2013 professional \nDomain Expertise \u2013 expert \nDomains \u2013 Machine Learning",
  "duration": 870,
  "published_at": "2020-03-06T12:30:17.000Z",
  "recorded": "",
  "speakers": [],
  "thumbnail_url": "https://i.ytimg.com/vi/vL-Tk4f1fg0/hqdefault.jpg",
  "title": "EuroSciPy 2019 Bilbao - Deep Learning for Understanding Human Multi-modal Behavior - Ricardo Manh\u00e3es",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=vL-Tk4f1fg0"
    }
  ]
}