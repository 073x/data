{
  "description": "EuroSciPy 2019 Bilbao \nSeptember 5, Thursday \nOteiza. Talk. 11.00\n\nExceeding Classical: Probabilistic Data Structures in Data Intensive Applications\nAndrii Gakhov\n\nWe interact with an increasing amount of data but classical data structures and algorithms can't fit our requirements anymore. This talk is to present the probabilistic algorithms and data structures and describe the main areas of their applications.\n\nNowadays, research in every scientific domain, from medicine to astronomy, is impossible without processing huge amounts of data to check hypotheses, find new relations, and make discoveries. However, the traditional technologies which include data structures and algorithms, become ineffective or require too many resources. This creates a demand for various optimization techniques, new data processing paradigms, and, finally, appropriate algorithms.\n\nThe presentation is dedicated to probabilistic data structures, that is a common name for advanced data structures based mostly on different hashing techniques. Unlike classical ones, these provide approximated answers but with reliable ways to estimate possible errors and uncertainty. They are designed for extremely low memory requirements, constant query time, and scaling, the factors that are essential for data applications. It is hard to imagine a branch that requires learning from data, where they cannot be applicable.\n\nThey are not necessarily new. Probably, everybody knows about the Bloom filter data structure, designed in the 70s, it efficiently solves the problem of performing membership queries (a task to decide whether some element belongs to the dataset or not) in a constant time without requirements to store all elements. This is an example of a probabilistic data structure, but there are much more that have been designed for various tasks in many domains.\n\nIn this talk, I explain the five most important problems in data processing that occurred in different domains but can be efficiently solved with probabilistic data structures and algorithms. We cover the membership querying, counting of unique elements, frequency and rank estimation in data streams, and similarity.\n\nEverybody interested in such a topic is welcome to participate in contributing a free and open-source Python (Cython) library called PDSA.\n\nProject Homepage / Git \u2013 https://pdsa.gakhov.com \nDomain Expertise \u2013 some \nDomains \u2013 Big Data, Robotics & IoT \nAbstract as a tweet \u2013 Learn why do you need to use probabilistic data structures and algorithms in your data applications. \nPython Skill Level \u2013 professional",
  "duration": 1689,
  "published_at": "2020-03-06T15:07:43.000Z",
  "recorded": "",
  "speakers": [],
  "thumbnail_url": "https://i.ytimg.com/vi/ZhY7lqug5yo/hqdefault.jpg",
  "title": "EuroSciPy 2019 Bilbao - Probabilistic Data Structures in Data Intensive Applications - Andrii Gakhov",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=ZhY7lqug5yo"
    }
  ]
}