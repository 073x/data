{
  "alias": "video/3334/accelerating-random-forests-in-scikit-learn",
  "category": "EuroScipy 2014",
  "copyright_text": "youtube",
  "description": "Random Forests are without contest one of the most robust, accurate and\nversatile tools for solving machine learning tasks. Implementing this\nalgorithm properly and efficiently remains however a challenging task\ninvolving issues that are easily overlooked if not considered with care.\nIn this talk, we present the Random Forests implementation developed\nwithin the Scikit-Learn machine learning library. In particular, we\ndescribe the iterative team efforts that led us to gradually improve our\ncodebase and eventually make Scikit-Learn's Random Forests one of the\nmost efficient implementations in the scientific ecosystem, across all\nlibraries and programming languages. Algorithmic and technical\noptimizations that have made this possible include:\n\n-  An efficient formulation of the decision tree algorithm, tailored for\n   Random Forests;\n-  Cythonization of the tree induction algorithm;\n-  CPU cache optimizations, through low-level organization of data into\n   contiguous memory blocks;\n-  Efficient multi-threading through GIL-free routines;\n-  A dedicated sorting procedure, taking into account the properties of\n   data;\n-  Shared pre-computations whenever critical.\n\nOverall, we believe that lessons learned from this case study extend to\na broad range of scientific applications and may be of interest to\nanybody doing data analysis in Python.\n",
  "duration": null,
  "id": 3334,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2014-10-22",
  "slug": "accelerating-random-forests-in-scikit-learn",
  "speakers": [
    "Gilles Louppe"
  ],
  "summary": "",
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/TqF0rKzvjm4/hqdefault.jpg",
  "title": "Accelerating Random Forests in Scikit Learn",
  "videos": [
    {
      "length": 0,
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=TqF0rKzvjm4"
    }
  ]
}
