{
  "copyright_text": "Standard YouTube License",
  "description": "PyData Berlin 2016\n\nThere are numerous examples of data anonymization gone horribly wrong - the most prominent one might be the netflix prize, where researchers were able to uniquely identify users by combining netflix user data with imdb reviews. Let's learn from their mistakes and look at some of the measures you can take to better anonymize data before you share it with others.\n\nOutline:\n\n- Look at some of the examples where data anonymization was broken and identify what went wrong\n- What is the state of the art for data anonymization and can you be sure to be safe if you follow it?\n- How does anonymization affect the possibilities for data mining/machine learning on the data?\n\nThis talk is aimed at people who want release open data or want to share sensitive data between departments.\n\nSlides: https://github.com/krasch/presentations/blob/master/pydata_Berlin_2016.pdf",
  "duration": 2148,
  "language": "eng",
  "recorded": "2016-05-31",
  "related_urls": [
    "https://github.com/krasch/presentations/blob/master/pydata_Berlin_2016.pdf"
  ],
  "speakers": [
    "Katharina Rasch"
  ],
  "tags": [
    "data anonymization"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/O3hxp117EHs/hqdefault.jpg",
  "title": "What every data scientist should know about data anonymization",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=O3hxp117EHs"
    }
  ]
}
